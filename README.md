# üöÄ Benchmark de Arquiteturas RAG para Not√≠cias Esportivas

Este reposit√≥rio cont√©m a implementa√ß√£o e o *benchmark* de quatro arquiteturas de Gera√ß√£o Aumentada por Recupera√ß√£o (**RAG**: *Retrieval Augmented Generation*) para um estudo de caso focado em informa√ß√µes factuais e din√¢micas (not√≠cias esportivas). O projeto utiliza containers Docker (PostgreSQL/pgvector e Neo4j) e a API da OpenAI para execu√ß√£o e avalia√ß√£o.

## üóÉÔ∏è Arquitetura do Projeto

O projeto est√° dividido em quatro pipelines de arquitetura e um m√≥dulo de prepara√ß√£o de dados (Scrapping).

| Diret√≥rio | Arquitetura | Base de Conhecimento (RK) | Descri√ß√£o do Pipeline |
| :--- | :--- | :--- | :--- |
| `baseline-llm` | **Baseline (LLM Puro)** | PostgreSQL (Apenas Resultados) | O LLM (GPT-3.5-Turbo) responde sem recupera√ß√£o de contexto, simulando a limita√ß√£o de conhecimento est√°tico. |
| `naive-rag` | **Naive RAG** | PostgreSQL (PGVector) | Recupera√ß√£o simples de `chunks` de texto por similaridade vetorial (`top_k`). |
| `advanced-rag` | **Advanced RAG** | PostgreSQL (PGVector) | Combina **busca por resumos** de documentos e **re-ranking** dos *chunks* recuperados (Sumariza√ß√£o + Re-ranking). |
| `graph-rag` | **Graph RAG** | Neo4j (Grafo) e PGSQL | Recupera√ß√£o h√≠brida (vetor + entidades) e expans√£o de contexto via grafo, traduzido para linguagem natural via LLM. |
| `web-scrapping` | **Dataset & QA Generation**| PostgreSQL (Scrapping DB) | M√≥dulo de coleta de not√≠cias e gera√ß√£o do conjunto de dados de avalia√ß√£o (P&R Simples, Multi-Contexto e Rejei√ß√£o Negativa). |

---

## ‚öôÔ∏è Configura√ß√£o do Ambiente

### 1. Pr√©-requisitos

* **Docker** e **Docker Compose** (Necess√°rio para todos os servi√ßos de banco de dados).
* **Python** (Vers√£o 3.9+).
* **Chave da API da OpenAI** (`sk-proj-XXXX...`).

### 2. Instala√ß√£o das Depend√™ncias Python

Instale os pacotes listados em `requirements.txt`:

```bash
pip install -r requirements.txt
```

### 3. Configura√ß√£o do Arquivo .env

Crie um arquivo chamado **`.env`** na **raiz** do projeto. Ele deve conter as credenciais de conex√£o para todos os servi√ßos, espelhando as configura√ß√µes definidas nos arquivos `docker-compose.yml`.

**IMPORTANTE:** Substitua os valores de `POSTGRES_PASSWORD` e `NEO4J_PASSWORD` pelos valores reais que voc√™ usar√° nos seus arquivos `docker-compose.yml`.

| Vari√°vel | Valor Exemplo (Baseado no `docker-compose`) | Descri√ß√£o |
| :--- | :--- | :--- |
| `OPENAI_API_KEY` | `sk-proj-SEUVALORAQUI...` | Chave da API para Embeddings e LLMs |
| **--- Naive RAG (Porta 5432) ---** | | |
| `PG_HOST` | `127.0.0.1` | Host |
| `PG_DATABASE` | `tcc_db` | Nome do DB |
| `PG_USER` | `bancoRAG` | Usu√°rio |
| `PG_PASSWORD` | `senha123` | **Senha (MUDAR!)** |
| `PG_PORT` | `5432` | Porta de acesso |
| **--- Scrapping DB (Porta 5433) ---** | | |
| `SCRAP_PG_DATABASE` | `wscrap_db` | Nome do DB |
| `SCRAP_PG_USER` | `wscrap_user` | Usu√°rio |
| `SCRAP_PG_PASSWORD` | `wscrap_pass` | **Senha (MUDAR!)** |
| `SCRAP_PG_HOST` | `127.0.0.1` | Host |
| `SCRAP_PG_PORT` | `5433` | Porta de acesso |
| **--- Baseline DB (Porta 5430) ---** | | |
| `BASELINE_PG_DATABASE` | `baseline_db` | Nome do DB |
| `BASELINE_PG_USER` | `bancoBaseline` | Usu√°rio |
| `BASELINE_PG_PASSWORD` | `senha123` | **Senha (MUDAR!)** |
| `BASELINE_PG_HOST` | `127.0.0.1` | Host |
| `BASELINE_PG_PORT` | `5430` | Porta de acesso |
| **--- Advanced RAG DB (Porta 5434) ---** | | |
| `ADV_PG_DATABASE` | `adv_rag_db` | Nome do DB |
| `ADV_PG_USER` | `adv_rag_user` | Usu√°rio |
| `ADV_PG_PASSWORD` | `adv_rag_password` | **Senha (MUDAR!)** |
| `ADV_PG_HOST` | `127.0.0.1` | Host |
| `ADV_PG_PORT` | `5434` | Porta de acesso |
| **--- Neo4j (Graph RAG) ---** | | |
| `NEO4J_URI` | `bolt://127.0.0.1:7687` | URI de conex√£o |
| `NEO4J_USER` | `neo4j` | Usu√°rio |
| `NEO4J_PASSWORD` | `1zc-WQh61g9abEjbDY9WatMXsAsm32HckKL1ikJQf0k` | **Senha (MUDAR!)** |
| **--- Graph RAG Evaluation DB (Porta 5429) ---** | | |
| `GRAPH_PG_USER` | `graph_user` | Usu√°rio |
| `GRAPH_PG_PASSWORD` | `graph_pass` | **Senha (MUDAR!)** |
| `GRAPH_PG_DATABASE` | `graph_rag_db` | Nome do DB |
| `GRAPH_PG_HOST` | `localhost` | Host |
| `GRAPH_PG_PORT` | `5429` | Porta de acesso |

### 4. Inicializa√ß√£o dos Bancos de Dados com Docker

Todos os bancos de dados PostgreSQL (`pgvector`) e o Neo4j devem ser iniciados antes de qualquer script Python ser executado.

#### Iniciar todos os servi√ßos (Naive, Baseline, Advanced e Graph):

Use os comandos abaixo para iniciar os containers de cada arquitetura, conforme configurado nos respectivos `docker-compose.yml`:

```bash
# Inicia Naive RAG (PostgreSQL na Porta 5432)
cd naive-rag && sudo docker compose up -d

# Inicia Baseline (PostgreSQL na Porta 5430)
cd ../baseline-llm && sudo docker compose up -d

# Inicia Advanced RAG (PostgreSQL na Porta 5434)
cd ../advanced-rag && sudo docker compose up -d

# Inicia Graph RAG (Neo4j: 7687, PostgreSQL de Avalia√ß√£o: 5429)
cd ../graph-rag && sudo docker compose up -d
```

#### Configurar √çndices Vetoriais no Neo4j:

Ap√≥s iniciar o Neo4j (acess√≠vel em `http://localhost:7474`), execute o seguinte Cypher no Neo4j Browser. Este √≠ndice √© crucial para a recupera√ß√£o vetorial dos chunks na arquitetura Graph RAG:

```Cypher
CREATE VECTOR INDEX chunk_embeddings IF NOT EXISTS
FOR (c:Chunk) ON (c.embedding)
OPTIONS {
  indexConfig: {
    `vector.dimensions`: 1536,
    `vector.similarity_function`: 'cosine'
  }
}
```

## üèÉ Fluxo de Execu√ß√£o (Reprodu√ß√£o do Benchmark)

### Fase 1: Cria√ß√£o do Dataset de Avalia√ß√£o (`web-scrapping`)

O `wscrap_db` (porta 5433) √© o *schema* central de onde todos os dados de avalia√ß√£o ser√£o puxados.

1.  **Coleta de Not√≠cias (Scraping):** Popula a tabela `scraping`.

    ```bash
    cd web-scrapping
    python 1.scrapper_ge.py
    ```

2.  **Gera√ß√£o de Perguntas Simples:** Cria perguntas na tabela `perguntas`.

    ```bash
    python 2.make-questions.py
    ```

3.  **Gera√ß√£o de Embeddings e Respostas Padr√£o (Ground Truth):** Gera respostas e *embeddings* de refer√™ncia para as perguntas simples.

    ```bash
    python 3.generate-embeddings-and-responses.py
    ```

4.  **Gera√ß√£o de P&R Complexas (Multi-Contexto e Rejei√ß√£o Negativa):** Adiciona as perguntas mais complexas de avalia√ß√£o, for√ßando a s√≠ntese de informa√ß√£o ou a recusa de resposta.

    ```bash
    python 4.generate_advanced_qa.py
    ```

### Fase 2: Ingest√£o de Conhecimento (RK)

Os dados do `wscrap_db` s√£o migrados e transformados nas bases de conhecimento de cada arquitetura.

1.  **Ingest√£o Naive RAG:** Divide o texto em *chunks* e armazena com *embeddings*.

    ```bash
    cd ../naive-rag
    python 1.generate_knowledge_base.py
    ```

2.  **Ingest√£o Advanced RAG:** Al√©m dos *chunks*, gera e armazena resumos de documentos com *embeddings*.

    ```bash
    cd ../advanced-rag
    python 1.generate_knowledge_base.py
    ```

3.  **Ingest√£o Graph RAG:** Transforma o texto em *chunks* e, usando LLM, em entidades e relacionamentos no Neo4j.

    ```bash
    cd ../graph-rag
    python 1.generate_knowledge_base.py
    ```

### Fase 3: Execu√ß√£o e Avalia√ß√£o do Pipeline

Execute o script `2.evaluate_rag.py` em cada diret√≥rio. Ele buscar√° as perguntas, executar√° o pipeline RAG/Baseline, calcular√° as m√©tricas (Similaridade, LLM Judge, RAGAS) e salvar√° os resultados na tabela `evaluation_results` do respectivo banco de dados.

| Arquitetura | Comando de Avalia√ß√£o |
| :--- | :--- |
| **Baseline (LLM Puro)** | `cd ../baseline-llm && python 2.evaluate_rag.py` |
| **Naive RAG** | `cd ../naive-rag && python 2.evaluate_rag.py` |
| **Advanced RAG** | `cd ../advanced-rag && python 2.evaluate_rag.py` |
| **Graph RAG** | `cd ../graph-rag && python 2.evaluate_rag.py` |

### Fase 4: Teste de Infer√™ncia e An√°lise

#### Testes de Infer√™ncia Simples (Opcional):

Execute para testar se a recupera√ß√£o e a gera√ß√£o est√£o funcionando corretamente em cada arquitetura:

```bash
# Testar Naive RAG
python naive-rag/inference.py

# Testar Advanced RAG
python advanced-rag/inference.py

# Testar Graph RAG
python graph-rag/inference.py
```

#### An√°lise do Dataset (Opcional):

Gera gr√°ficos e estat√≠sticas sobre a distribui√ß√£o e o conte√∫do do conjunto de dados.

```bash
cd ../web-scrapping
python 5.analyze_dataset.py
```